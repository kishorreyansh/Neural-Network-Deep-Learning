# -*- coding: utf-8 -*-
"""700744713_Assignment6_NNDL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19_OfiQk5t-pAymzXC80R0B9foK__8cqU

1. Use the use case in the class:
"""

import pandas as pd
import numpy as np
from keras.models import Sequential
from keras.layers import Dense
from sklearn.model_selection import train_test_split

# Loading diabetes data set
diabetes_data = pd.read_csv("diabetes.csv", header=None).values

features = diabetes_data[:, 0:8]
target = diabetes_data[:, 8]

X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.25, random_state=87)

np.random.seed(155)

sequential_model = Sequential()

sequential_model.add(Dense(20, input_dim=8, activation='relu'))  # hidden layer
sequential_model.add(Dense(1, activation='sigmoid'))  # output layer
sequential_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

history = sequential_model.fit(X_train, y_train, epochs=100, initial_epoch=0, verbose=1)

print("Model Summary: ")
print(sequential_model.summary())

evaluation_results = sequential_model.evaluate(X_test, y_test)
print("\nEvaluation Result (loss, accuracy):", evaluation_results)

"""PROBLEM 1

1 a. Adding more Dense Layers and checking the output.
"""

import pandas as pd
from keras.models import Sequential
from keras.layers import Dense
from sklearn.model_selection import train_test_split
import numpy as np

# Load dataset
dataset = pd.read_csv("diabetes.csv", header=None).values

X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8],
                                                    test_size=0.25, random_state=87)
np.random.seed(155)

sequential_model = Sequential() # create model
sequential_model.add(Dense(20, input_dim=8, activation='relu'))
sequential_model.add(Dense(10, activation='relu'))  # Additional hidden layer
sequential_model.add(Dense(5, activation='relu'))   # Additional hidden layer
sequential_model.add(Dense(1, activation='sigmoid')) # output layer
sequential_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
history = sequential_model.fit(X_train, Y_train, epochs=100,
                                     initial_epoch=0, verbose=1)

print("Model Summary: ")
print(sequential_model.summary())

evaluation_results = sequential_model.evaluate(X_test, y_test)
print("\nEvaluation Result (loss, accuracy):", evaluation_results)

"""Changing the data set to Breast Cancer"""

import pandas as pd
from keras.models import Sequential
from keras.layers import Dense
from sklearn.model_selection import train_test_split
import numpy as np
from sklearn.preprocessing import LabelEncoder
# Load dataset
dataset = pd.read_csv("breastcancer.csv")
dataset.drop(['id'], axis=1, inplace=True)
del dataset['Unnamed: 32']

X = dataset.iloc[:, 2:].values
Y = dataset.iloc[:, 1].values
label = LabelEncoder()
Y = label.fit_transform(Y)

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25)
np.random.seed(155)

sequential_model = Sequential()  # create model
sequential_model.add(Dense(20, input_dim=29, activation='relu'))  # hidden layer
sequential_model.add(Dense(1, activation='sigmoid'))  # output layer
sequential_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
history = sequential_model.fit(X_train, Y_train, epochs=100, initial_epoch=0, verbose=1)

print("Model Summary: ")
print(sequential_model.summary())

evaluation_results = sequential_model.evaluate(X_test, Y_test)
print("\nEvaluation Result (loss, accuracy):", evaluation_results)

"""NORMALIZING THE DATA USING STANDARD SCALER"""

import pandas as pd
from keras.models import Sequential
from keras.layers import Dense
from sklearn.model_selection import train_test_split
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler

# Load dataset
dataset = pd.read_csv("breastcancer.csv")
dataset.drop(columns=['id', 'Unnamed: 32'], inplace=True)

X = dataset.iloc[:, 2:].values
Y = LabelEncoder().fit_transform(dataset.iloc[:, 1])

# Splitting data into train and test sets
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=155)

# Standardize features
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

# Define model
sequential_model = Sequential()
sequential_model.add(Dense(20, input_dim=29, activation='relu'))  # Hidden layer
sequential_model.add(Dense(1, activation='sigmoid'))  # Output layer
sequential_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train model
my_first_nn_fitted = sequential_model.fit(X_train, Y_train, epochs=100, initial_epoch=0, verbose=1)

# Print model summary
print(sequential_model.summary())

# Evaluate model
evaluation_results = sequential_model.evaluate(X_test, Y_test)
print("\nEvaluation Result (loss, accuracy):", evaluation_results)

"""2.	Use Image Classification on the hand written digits data set (mnist)"""

from keras import Sequential
from keras.datasets import mnist
import numpy as np
from keras.layers import Dense
from keras.utils import to_categorical

(train_images,train_labels),(test_images, test_labels) = mnist.load_data()

print(train_images.shape[1:])
#process the data
#1. convert each image of shape 28*28 to 784 dimensional which will be fed to the network as a single feature
dimData = np.prod(train_images.shape[1:])
print(dimData)
train_data = train_images.reshape(train_images.shape[0],dimData)
test_data = test_images.reshape(test_images.shape[0],dimData)

#convert data to float and scale values between 0 and 1
train_data = train_data.astype('float')
test_data = test_data.astype('float')
#scale data
train_data /=255.0
test_data /=255.0
#change the labels from integer to one-hot encoding. to_categorical is doing the same thing as LabelEncoder()
train_labels_one_hot = to_categorical(train_labels)
test_labels_one_hot = to_categorical(test_labels)

#creating network
model = Sequential()
model.add(Dense(512, activation='relu', input_shape=(dimData,)))
model.add(Dense(512, activation='relu'))
model.add(Dense(10, activation='softmax'))

model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])
history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,
                   validation_data=(test_data, test_labels_one_hot))

"""Plotting the loss and accuracy for both training data and validation data using the history object in the source code:"""

from keras import Sequential
from keras.datasets import mnist
import numpy as np
from keras.layers import Dense
from keras.utils import to_categorical

(train_images,train_labels),(test_images, test_labels) = mnist.load_data()

print(train_images.shape[1:])
#process the data
#1. convert each image of shape 28*28 to 784 dimensional which will be fed to the network as a single feature
dimData = np.prod(train_images.shape[1:])
print(dimData)
train_data = train_images.reshape(train_images.shape[0],dimData)
test_data = test_images.reshape(test_images.shape[0],dimData)

#convert data to float and scale values between 0 and 1
train_data = train_data.astype('float')
test_data = test_data.astype('float')
#scale data
train_data /=255.0
test_data /=255.0
#change the labels frominteger to one-hot encoding. to_categorical is doing the same thing as LabelEncoder()
train_labels_one_hot = to_categorical(train_labels)
test_labels_one_hot = to_categorical(test_labels)

#creating network
model = Sequential()
model.add(Dense(512, activation='relu', input_shape=(dimData,)))
model.add(Dense(512, activation='relu'))
model.add(Dense(10, activation='softmax'))

model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])
history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,
                   validation_data=(test_data, test_labels_one_hot))

import matplotlib.pyplot as plt

# Plot training & validation loss values
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

# Plot training & validation accuracy values
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

"""Plot one of the images in the test data, and then do inferencing to check what is the prediction of the model
on that single image
"""

from keras import Sequential
from keras.datasets import mnist
import numpy as np
from keras.layers import Dense
from keras.utils import to_categorical

(train_images,train_labels),(test_images, test_labels) = mnist.load_data()

print(train_images.shape[1:])
#process the data
#1. convert each image of shape 28*28 to 784 dimensional which will be fed to the network as a single feature
dimData = np.prod(train_images.shape[1:])
print(dimData)
train_data = train_images.reshape(train_images.shape[0],dimData)
test_data = test_images.reshape(test_images.shape[0],dimData)

#convert data to float and scale values between 0 and 1
train_data = train_data.astype('float')
test_data = test_data.astype('float')
#scale data
train_data /=255.0
test_data /=255.0
#change the labels frominteger to one-hot encoding. to_categorical is doing the same thing as LabelEncoder()
train_labels_one_hot = to_categorical(train_labels)
test_labels_one_hot = to_categorical(test_labels)

#creating network
model = Sequential()
model.add(Dense(512, activation='relu', input_shape=(dimData,)))
model.add(Dense(512, activation='relu'))
model.add(Dense(10, activation='softmax'))

model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])
history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,
                   validation_data=(test_data, test_labels_one_hot))

import matplotlib.pyplot as plt

# Plot one image from the test data
plt.figure()
plt.imshow(test_images[0], cmap='gray')
plt.title(f"True Label: {test_labels[0]}")

# Perform inference on the single image
image = test_data[0].reshape(1, dimData)
prediction = model.predict(image)
predicted_label = np.argmax(prediction)

print(f"Predicted Label: {predicted_label}")

"""We had used 2 hidden layers and Relu activation. Try to change the number of hidden layer and the
activation to tanh or sigmoid and see what happens.
"""

from keras import Sequential
from keras.datasets import mnist
import numpy as np
from keras.layers import Dense
from keras.utils import to_categorical

(train_images,train_labels),(test_images, test_labels) = mnist.load_data()

print(train_images.shape[1:])
#process the data
#1. convert each image of shape 28*28 to 784 dimensional which will be fed to the network as a single feature
dimData = np.prod(train_images.shape[1:])
print(dimData)
train_data = train_images.reshape(train_images.shape[0],dimData)
test_data = test_images.reshape(test_images.shape[0],dimData)

#convert data to float and scale values between 0 and 1
train_data = train_data.astype('float')
test_data = test_data.astype('float')
#scale data
train_data /=255.0
test_data /=255.0
#change the labels frominteger to one-hot encoding. to_categorical is doing the same thing as LabelEncoder()
train_labels_one_hot = to_categorical(train_labels)
test_labels_one_hot = to_categorical(test_labels)

#creating network
model = Sequential()
model.add(Dense(512, activation='tanh', input_shape=(dimData,)))  # Change activation to 'tanh'
model.add(Dense(256, activation='tanh'))  # Add another hidden layer with 'tanh'
model.add(Dense(128, activation='tanh'))  # Add one more hidden layer with 'tanh'
model.add(Dense(10, activation='softmax'))

model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])
history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,
                   validation_data=(test_data, test_labels_one_hot))

"""Run the same code without scaling the images"""

from keras import Sequential
from keras.datasets import mnist
import numpy as np
from keras.layers import Dense
from keras.utils import to_categorical

(train_images,train_labels),(test_images, test_labels) = mnist.load_data()

print(train_images.shape[1:])
#process the data
#1. convert each image of shape 28*28 to 784 dimensional which will be fed to the network as a single feature
dimData = np.prod(train_images.shape[1:])
print(dimData)
train_data = train_images.reshape(train_images.shape[0],dimData)
test_data = test_images.reshape(test_images.shape[0],dimData)

#convert data to float and scale values between 0 and 1
train_data = train_data.astype('float')
test_data = test_data.astype('float')
#scale data
#train_data /=255.0
#test_data /=255.0
#change the labels frominteger to one-hot encoding. to_categorical is doing the same thing as LabelEncoder()
train_labels_one_hot = to_categorical(train_labels)
test_labels_one_hot = to_categorical(test_labels)

#creating network
model = Sequential()
model.add(Dense(512, activation='relu', input_shape=(dimData,)))
model.add(Dense(512, activation='relu'))
model.add(Dense(10, activation='softmax'))

model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])
history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,
                   validation_data=(test_data, test_labels_one_hot))